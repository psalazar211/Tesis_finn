{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5280f97b-b2a9-4e20-9d70-6e2b59f0703f",
   "metadata": {},
   "source": [
    "# Train a Resnet on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8c496b-d2df-4285-8d7e-0e0a40062580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d6b941-e6dd-4d38-812b-6f21b816b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e22fa4-9323-424e-a28f-d304a0aacb7b",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fe3397-841f-4068-849e-18dcde49c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "class GetTransforms():\n",
    "    '''Returns a list of transformations when type as requested amongst train/test\n",
    "       Transforms('train') = list of transforms to apply on training data\n",
    "       Transforms('test') = list of transforms to apply on testing data'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def trainparams(self):\n",
    "        train_transformations = [ #resises the image so it can be perfect for our model.\n",
    "            transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "            transforms.RandomRotation((-7,7)),     #Rotates the image to a specified angel\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "            transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)) #Normalize all the images\n",
    "            ]\n",
    "\n",
    "        return train_transformations\n",
    "\n",
    "    def testparams(self):\n",
    "        test_transforms = [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261))\n",
    "        ]\n",
    "        return test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab893734-9e43-450d-9cf5-30502f038949",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = GetTransforms()\n",
    "train_transforms = transforms.Compose(transformations.trainparams())\n",
    "test_transforms = transforms.Compose(transformations.testparams())\n",
    "\n",
    "\n",
    "class GetCIFAR10_TrainData():\n",
    "    def __init__(self, dir_name:str):\n",
    "        self.dirname = dir_name\n",
    "\n",
    "    def download_train_data(self):\n",
    "        return datasets.CIFAR10('resnet18/data', train=True, download=True, transform=train_transforms)\n",
    "\n",
    "    def download_test_data(self):\n",
    "        return datasets.CIFAR10('resnet18/data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5961330-5bfb-4a5c-bfe0-46b48e6d5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data = GetCIFAR10_TrainData(os.chdir(\"..\"))\n",
    "trainset = data.download_train_data()\n",
    "testset = data.download_test_data()\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=592,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=592,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3ae79-5d6d-417c-b7f5-719f50e98af4",
   "metadata": {},
   "source": [
    "## Define a PyTorch Device\n",
    "\n",
    "GPUs can significantly speed-up training of deep neural networks. We check for availability of a GPU and if so define it as target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ff185a-f49b-477e-ad42-a21e8731e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ddfa27-1f48-40e6-ad0d-a723197992aa",
   "metadata": {},
   "source": [
    "## Define the MLP Model\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6a86ac-f496-4392-bc16-9d55ede59647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                 nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=200, dropout=0.0):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout=self.dropout))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "        \n",
    "def ResNet18(num_classes=10, dropout=0.0):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "model = model = ResNet18(num_classes=10)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3301f9-b1ad-4b02-93e6-a456ce7e21f7",
   "metadata": {},
   "source": [
    "## Train the CNN\n",
    "\n",
    "We provide two options for training below: you can opt for training the model from scratch (slower) or use a pre-trained model (faster). The first option will give more insight into how the training process works, while the second option will likely give better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8f507a-9a55-4916-8190-0ac89a61fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch,\n",
    "          l1_decay, l2_decay, train_losses, train_accs, scheduler=None):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  avg_loss = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "    # Calculate loss\n",
    "    loss = criterion(y_pred, target)\n",
    "    if l1_decay > 0:\n",
    "      l1_loss = 0\n",
    "      for param in model.parameters():\n",
    "        l1_loss += torch.norm(param,1)\n",
    "      loss += l1_decay * l1_loss\n",
    "    if l2_decay > 0:\n",
    "      l2_loss = 0\n",
    "      for param in model.parameters():\n",
    "        l2_loss += torch.norm(param,2)\n",
    "      loss += l2_decay * l2_loss\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if scheduler:\n",
    "      scheduler.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "    avg_loss += loss.item()\n",
    "\n",
    "    pbar_str = f'Loss={loss.item():0.5f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}'\n",
    "    if l1_decay > 0:\n",
    "      pbar_str = f'L1_loss={l1_loss.item():0.3f} %s' % (pbar_str)\n",
    "    if l2_decay > 0:\n",
    "      pbar_str = f'L2_loss={l2_loss.item():0.3f} %s' % (pbar_str)\n",
    "\n",
    "    pbar.set_description(desc= pbar_str)\n",
    "\n",
    "  avg_loss /= len(train_loader)\n",
    "  avg_acc = 100*correct/processed\n",
    "  train_accs.append(avg_acc)\n",
    "  train_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770f8448-7323-420a-a4ad-f45de333982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"%s\" % i for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83e26f-d7c2-4132-bc15-983648cbd3b5",
   "metadata": {},
   "source": [
    "## Test the CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d190b141-b5bc-46be-b059-3b7b5a0d6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, classes, test_losses, test_accs,\n",
    "         misclassified_imgs, correct_imgs, is_last_epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss +=criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            is_correct = pred.eq(target.view_as(pred))\n",
    "            if is_last_epoch:\n",
    "              misclassified_inds = (is_correct==0).nonzero()[:,0]\n",
    "              for mis_ind in misclassified_inds:\n",
    "                if len(misclassified_imgs) == 25:\n",
    "                  break\n",
    "                misclassified_imgs.append({\n",
    "                    \"target\": target[mis_ind].cpu().numpy(),\n",
    "                    \"pred\": pred[mis_ind][0].cpu().numpy(),\n",
    "                    \"img\": data[mis_ind]\n",
    "                })\n",
    "              \n",
    "              correct_inds = (is_correct==1).nonzero()[:,0]\n",
    "              for ind in correct_inds:\n",
    "                if len(correct_imgs) == 25:\n",
    "                  break\n",
    "                correct_imgs.append({\n",
    "                    \"target\": target[ind].cpu().numpy(),\n",
    "                    \"pred\": pred[ind][0].cpu().numpy(),\n",
    "                    \"img\": data[ind]\n",
    "                })\n",
    "            correct += is_correct.sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    if test_acc >= 90.0:\n",
    "        classwise_acc(model, device, test_loader, classes)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1056b5-781e-496c-b069-2134c6e31d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classwise_acc(model, device, test_loader, classes):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # print class-wise test accuracies\n",
    "    print()\n",
    "    for i in range(10):\n",
    "      print('Accuracy of %5s : %2d %%' % (\n",
    "          classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55548f9d-a25c-428a-a084-0f683bfe96c6",
   "metadata": {},
   "source": [
    "## Train the CNN\n",
    "\n",
    "We provide two options for training below: you can opt for training the model from scratch (slower) or use a pre-trained model (faster). The first option will give more insight into how the training process works, while the second option will likely give better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bf2e4a-9a11-4191-b727-04019992aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 (LR: 0.002000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L2_loss=458.849 Loss=4.34219 Batch_id=20 Accuracy=17.57:  25%|▏| 21/85 [00:31<01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m       test(model, device, testloader, criterion, classes, test_losses,\n\u001b[1;32m     18\u001b[0m            test_accs, misclassified_imgs, correct_imgs, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# train and test the model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(l1_decay, l2_decay)\u001b[0m\n\u001b[1;32m     13\u001b[0m lr_trend\u001b[38;5;241m.\u001b[39mappend(optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr_trend[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[43ml1_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml2_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test(model, device, testloader, criterion, classes, test_losses,\n\u001b[1;32m     18\u001b[0m      test_accs, misclassified_imgs, correct_imgs, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, epoch, l1_decay, l2_decay, train_losses, train_accs, scheduler)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Update pbar-tqdm\u001b[39;00m\n\u001b[1;32m     39\u001b[0m pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m     42\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum= 0.9)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(trainloader),\n",
    "                       epochs=epochs, div_factor=10, final_div_factor=10,\n",
    "                       pct_start=10/epochs)\n",
    "\n",
    "test_losses, train_losses, test_accs, train_accs = [], [], [], []\n",
    "misclassified_imgs, correct_imgs = [], []\n",
    "lr_trend = []\n",
    "def run(l1_decay=0.0, l2_decay=0.0):\n",
    "  for epoch in range(epochs):\n",
    "      lr_trend.append(optimizer.param_groups[0]['lr'])\n",
    "      print(f\"EPOCH: {epoch+1} (LR: {lr_trend[-1]:0.6f})\")\n",
    "      train(model, device, trainloader, criterion, optimizer, epoch,\n",
    "            l1_decay,l2_decay, train_losses, train_accs, scheduler)\n",
    "      test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)\n",
    "\n",
    "# train and test the model\n",
    "run(l1_decay=0, l2_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e2a92-78e7-47c9-b50c-abff00385b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"CIFAR/models/resnet18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887e813-c7c2-4274-889a-f9b60d18e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model back to it's target device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Test for accuracy\n",
    "test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720a0ac-8e09-4859-a1b2-169e33a621ca",
   "metadata": {},
   "source": [
    "## Define the Quantized MLP Model wights 8 bits\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4a781-365e-47b6-8e8b-a4c060bac2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantConv2d, QuantLinear\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = QuantConv2d(planes, self.expansion*planes, kernel_size=1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=200, dropout=0.0):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = QuantConv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = QuantLinear(512*block.expansion, num_classes, bias=True)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout=self.dropout))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10, dropout=0.0):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "model = ResNet18(num_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981928a3-8790-4bea-88da-5438e0dae671",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum= 0.9)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(trainloader),\n",
    "                       epochs=epochs, div_factor=10, final_div_factor=10,\n",
    "                       pct_start=10/epochs)\n",
    "\n",
    "\n",
    "test_losses, train_losses, test_accs, train_accs = [], [], [], []\n",
    "misclassified_imgs, correct_imgs = [], []\n",
    "lr_trend = []\n",
    "def run(l1_decay=0.0, l2_decay=0.0):\n",
    "  for epoch in range(epochs):\n",
    "      lr_trend.append(optimizer.param_groups[0]['lr'])\n",
    "      print(f\"EPOCH: {epoch+1} (LR: {lr_trend[-1]:0.6f})\")\n",
    "      train(model, device, trainloader, criterion, optimizer, epoch,\n",
    "            l1_decay,l2_decay, train_losses, train_accs, scheduler)\n",
    "      test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)\n",
    "\n",
    "# train and test the model\n",
    "run(l1_decay=0, l2_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8f372-483f-4844-b1d3-d00463e6b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"CIFAR/models/quentresnet18_weight8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93ffa6-8fc8-4801-afbf-11e2cf68fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model back to it's target device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Test for accuracy\n",
    "test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bba03-fd01-4471-bb3e-983ce1af9c4d",
   "metadata": {},
   "source": [
    "## Define the Quantized MLP Model weights 4 bits\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afef79-b56d-4d70-bf99-e0ccf5b57a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantConv2d, QuantLinear\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weight_bit_width = 4\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True, weight_bit_width=weight_bit_width),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = QuantConv2d(planes, self.expansion*planes, kernel_size=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True, weight_bit_width=weight_bit_width),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=200, dropout=0.0):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = QuantConv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = QuantLinear(512*block.expansion, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout=self.dropout))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10, dropout=0.0):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "model = ResNet18(num_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0dd44-edbf-4f4b-ba4c-faf1cc63d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum= 0.9)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(trainloader),\n",
    "                       epochs=epochs, div_factor=10, final_div_factor=10,\n",
    "                       pct_start=10/epochs)\n",
    "\n",
    "\n",
    "test_losses, train_losses, test_accs, train_accs = [], [], [], []\n",
    "misclassified_imgs, correct_imgs = [], []\n",
    "lr_trend = []\n",
    "def run(l1_decay=0.0, l2_decay=0.0):\n",
    "  for epoch in range(epochs):\n",
    "      lr_trend.append(optimizer.param_groups[0]['lr'])\n",
    "      print(f\"EPOCH: {epoch+1} (LR: {lr_trend[-1]:0.6f})\")\n",
    "      train(model, device, trainloader, criterion, optimizer, epoch,\n",
    "            l1_decay,l2_decay, train_losses, train_accs, scheduler)\n",
    "      test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)\n",
    "\n",
    "# train and test the model\n",
    "run(l1_decay=0, l2_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5bde9-9bc1-494c-bf86-ec8ea9e21712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"CIFAR/models/quentresnet18_weight4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1197813-fbc1-43b9-9b3b-41a3ad1b7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model back to it's target device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Test for accuracy\n",
    "test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc131c12-4689-4244-9529-b0ac7ab6ea01",
   "metadata": {},
   "source": [
    "## Define the Quantized MLP Model weights 2 bits\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba1e85-66f8-4cef-9e3d-878ba9f44055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantConv2d, QuantLinear\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weight_bit_width = 2\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True, weight_bit_width=weight_bit_width),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = QuantConv2d(in_planes, planes, kernel_size=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = QuantConv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = QuantConv2d(planes, self.expansion*planes, kernel_size=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                QuantConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True, weight_bit_width=weight_bit_width),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=200, dropout=0.0):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = QuantConv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True, weight_bit_width=weight_bit_width)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = QuantLinear(512*block.expansion, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout=self.dropout))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.dropout(out, p=self.dropout)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10, dropout=0.0):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "model = ResNet18(num_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e758ad-1f14-44a3-9466-9fd8b296ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum= 0.9)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(trainloader),\n",
    "                       epochs=epochs, div_factor=10, final_div_factor=10,\n",
    "                       pct_start=10/epochs)\n",
    "\n",
    "\n",
    "test_losses, train_losses, test_accs, train_accs = [], [], [], []\n",
    "misclassified_imgs, correct_imgs = [], []\n",
    "lr_trend = []\n",
    "def run(l1_decay=0.0, l2_decay=0.0):\n",
    "  for epoch in range(epochs):\n",
    "      lr_trend.append(optimizer.param_groups[0]['lr'])\n",
    "      print(f\"EPOCH: {epoch+1} (LR: {lr_trend[-1]:0.6f})\")\n",
    "      train(model, device, trainloader, criterion, optimizer, epoch,\n",
    "            l1_decay,l2_decay, train_losses, train_accs, scheduler)\n",
    "      test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)\n",
    "\n",
    "# train and test the model\n",
    "run(l1_decay=0, l2_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a4527-2cf0-461c-90db-e345dc49736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"CIFAR/models/quentresnet18_weight2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac46001-37be-42fd-be40-b962d218bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model back to it's target device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Test for accuracy\n",
    "test(model, device, testloader, criterion, classes, test_losses,\n",
    "           test_accs, misclassified_imgs, correct_imgs, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01cddb-b33f-4908-96da-5342286cf82f",
   "metadata": {},
   "source": [
    "## Define the Quantized MLP Model weights 2 bits activatio\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d04bca-bc06-4a90-a800-c42305c80903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
